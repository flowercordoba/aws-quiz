export const exam = [
  {
    id: 1, // 游댠 ID en n칰mero
    title: "Examen de AWS AI",
    description: "Pon a prueba tus conocimientos sobre los servicios de IA en AWS.",
    image: "https://images.unsplash.com/photo-1628296499994-70face79ab36?q=80&w=1973&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D",
    questions: [
      {
        question: "쯈u칠 servicio de Amazon SageMaker ayuda a construir datasets de entrenamiento etiquetados y de alta calidad?",
        options: ["Amazon SageMaker Ground Truth", "Amazon Bedrock", "Amazon Rekognition", "Amazon Comprehend"],
        answers: ["Amazon SageMaker Ground Truth"],
        multipleCorrect: false,
        explanation: "Amazon SageMaker Ground Truth permite crear datasets de entrenamiento de alta calidad con anotaciones autom치ticas y supervisadas."
      },
      {
        question: "쮺u치l de los siguientes casos de uso NO es adecuado para Amazon Rekognition?",
        options: ["Enable multilingual user experiences in your applications", "Amazon Bedrock", "Amazon Rekognition", "Amazon Comprehend"],
        answers: ["Enable multilingual user experiences in your applications"],
        multipleCorrect: false,
        explanation: "Amazon Rekognition est치 dise침ado para an치lisis de im치genes y videos, mientras que la creaci칩n de experiencias multiling칲es es mejor con Amazon Translate."
      },
      {
        question: "쯈u칠 servicios de AWS se recomiendan para realizar an치lisis de sentimientos en rese침as de clientes? (Seleccionar dos)",
        options: ["Amazon Comprehend", "Amazon Bedrock", "Amazon Rekognition", "Amazon Polly"],
        answers: ["Amazon Comprehend", "Amazon Bedrock"],
        multipleCorrect: true,
        explanation: "Amazon Comprehend es un servicio de procesamiento de lenguaje natural que permite el an치lisis de sentimientos, mientras que Amazon Bedrock proporciona modelos de IA generativa que pueden mejorar este an치lisis."
      },
      {
        question: "쮺u치les son las mejores estrategias para especializar un modelo fundacional en un dominio espec칤fico? (Seleccionar dos)",
        options: ["Continued Pre-Training", "Domain Adaptation Fine-Tuning", "Data Augmentation", "Feature Engineering"],
        answers: ["Continued Pre-Training", "Domain Adaptation Fine-Tuning"],
        multipleCorrect: true,
        explanation: "El preentrenamiento continuo y el ajuste fino para adaptaci칩n de dominio son estrategias clave para especializar un modelo en un contexto espec칤fico."
      },
      {
        question: "쯈u칠 base de datos vectorial es compatible de forma nativa con Amazon Bedrock para almacenar embeddings?",
        options: ["OpenSearch Serverless vector store", "Amazon DynamoDB", "Amazon Aurora", "Amazon Redshift"],
        answers: ["OpenSearch Serverless vector store"],
        multipleCorrect: false,
        explanation: "Amazon Bedrock es compatible con OpenSearch Serverless como soluci칩n para almacenar embeddings de forma eficiente."
      },
      {
        question: "쮺칩mo funciona el aprendizaje por refuerzo?",
        options: [
          "Un modelo se entrena con un gran conjunto de datos etiquetados",
          "El aprendizaje por refuerzo implica que un agente interact칰e con un entorno, tome acciones y reciba recompensas o penalizaciones, aprendiendo una pol칤tica para maximizar las recompensas acumuladas en el tiempo",
          "Optimiza la selecci칩n de caracter칤sticas mediante t칠cnicas estad칤sticas",
          "Usa un modelo preentrenado para clasificar nuevos datos sin entrenamiento adicional"
        ],
        answers: [
          "El aprendizaje por refuerzo implica que un agente interact칰e con un entorno, tome acciones y reciba recompensas o penalizaciones, aprendiendo una pol칤tica para maximizar las recompensas acumuladas en el tiempo"
        ],
        multipleCorrect: false,
        explanation: "El aprendizaje por refuerzo permite a un agente aprender estrategias 칩ptimas a trav칠s de la interacci칩n con su entorno."
      },
      {
        question: "쯈u칠 enfoque es m치s adecuado para optimizar varios modelos de machine learning compartiendo informaci칩n entre ellos?",
        options: ["Transfer Learning", "Hyperparameter Optimization", "Federated Learning", "Feature Engineering"],
        answers: ["Transfer Learning"],
        multipleCorrect: false,
        explanation: "Transfer Learning permite aprovechar el conocimiento aprendido en un modelo previo para mejorar el rendimiento de otro modelo en un nuevo dominio."
      },
      {
        question: "쮺u치les son las caracter칤sticas clave de Amazon SageMaker JumpStart? (Seleccionar dos)",
        options: [
          "Los modelos preentrenados son completamente personalizables para tu caso de uso con tus datos",
          "Puedes evaluar, comparar y seleccionar Modelos Fundacionales r치pidamente con m칠tricas predefinidas de calidad y responsabilidad",
          "Solo admite modelos de terceros sin capacidad de ajuste",
          "No permite entrenar modelos personalizados"
        ],
        answers: [
          "Los modelos preentrenados son completamente personalizables para tu caso de uso con tus datos",
          "Puedes evaluar, comparar y seleccionar Modelos Fundacionales r치pidamente con m칠tricas predefinidas de calidad y responsabilidad"
        ],
        multipleCorrect: true,
        explanation: "Amazon SageMaker JumpStart facilita la selecci칩n y personalizaci칩n de modelos fundacionales preentrenados."
      },
      {
        question: "쮺u치l es un caso de uso v치lido para un modelo de IA generativa?",
        options: [
          "Usar IA generativa para crear im치genes fotorrealistas a partir de descripciones textuales",
          "Clasificaci칩n de transacciones fraudulentas en tiempo real",
          "Segmentaci칩n de clientes para marketing basado en clustering",
          "Optimizaci칩n de rutas en log칤stica"
        ],
        answers: ["Usar IA generativa para crear im치genes fotorrealistas a partir de descripciones textuales"],
        multipleCorrect: false,
        explanation: "La IA generativa es especialmente 칰til en tareas como la creaci칩n de im치genes y textos nuevos a partir de entradas textuales."
      },
      {
        question: "쮺u치les son los componentes clave de una buena t칠cnica de prompting en el contexto de generaci칩n de IA?",
        options: ["Instrucciones", "Contexto", "Datos de entrada", "Indicador de salida"],
        answers: ["Instrucciones", "Contexto", "Datos de entrada", "Indicador de salida"],
        multipleCorrect: true,
        explanation: "Una buena estrategia de prompting requiere instrucciones claras, contexto relevante, datos de entrada adecuados y un indicador de salida preciso."
      },
      {
        question: "En el modelo de responsabilidad compartida de AWS, 쯖u치l es la divisi칩n de responsabilidades entre el cliente y AWS?",
        options: [
          "AWS es responsable de la seguridad 'de' la nube, mientras que el cliente es responsable de la seguridad 'en' la nube",
          "El cliente es completamente responsable de la seguridad de su infraestructura en AWS",
          "AWS gestiona la seguridad de las aplicaciones del cliente",
          "La seguridad de la nube es exclusivamente responsabilidad del cliente"
        ],
        answers: ["AWS es responsable de la seguridad 'de' la nube, mientras que el cliente es responsable de la seguridad 'en' la nube"],
        multipleCorrect: false,
        explanation: "AWS asegura la infraestructura subyacente, mientras que el cliente debe gestionar la seguridad de sus datos y aplicaciones en la nube."
      },
      {
        question: "쯈u칠 soluci칩n es m치s adecuada para habilitar el monitoreo detallado de invocaciones de modelos en Amazon Bedrock?",
        options: [
          "Habilitar el registro de invocaciones de modelos",
          "Implementar Amazon CloudWatch",
          "Utilizar AWS X-Ray",
          "Aplicar AWS Shield"
        ],
        answers: ["Habilitar el registro de invocaciones de modelos"],
        multipleCorrect: false,
        explanation: "El registro de invocaciones de modelos permite un monitoreo detallado de todas las solicitudes y respuestas en Amazon Bedrock."
      },
      {
        question: "쯈u칠 modelo de embeddings es m치s adecuado para diferenciar significados contextuales de palabras en frases distintas?",
        options: ["BERT", "Word2Vec", "GloVe", "FastText"],
        answers: ["BERT"],
        multipleCorrect: false,
        explanation: "BERT (Bidirectional Encoder Representations from Transformers) captura el contexto bidireccional, diferenciando significados en distintos contextos."
      },
      {
        question: "쮺u치l es una de las principales ventajas de usar IA generativa en el entorno de AWS?",
        options: [
          "Automatizaci칩n de la creaci칩n de datos nuevos a partir de patrones existentes",
          "Optimizaci칩n de infraestructura para bases de datos SQL",
          "Reducci칩n de costos en almacenamiento en Amazon S3",
          "Aceleraci칩n de la indexaci칩n de datos en Amazon OpenSearch"
        ],
        answers: ["Automatizaci칩n de la creaci칩n de datos nuevos a partir de patrones existentes"],
        multipleCorrect: false,
        explanation: "La IA generativa permite la creaci칩n autom치tica de contenido, lo que impulsa la innovaci칩n y mejora la productividad."
      },
      {
        question: "쮺u치les son ejemplos de aprendizaje supervisado? (Seleccionar dos)",
        options: [
          "Red neuronal",
          "Regresi칩n lineal",
          "Algoritmo gen칠tico",
          "Aprendizaje por refuerzo"
        ],
        answers: ["Red neuronal", "Regresi칩n lineal"],
        multipleCorrect: true,
        explanation: "El aprendizaje supervisado implica entrenamiento con datos etiquetados, y ejemplos comunes son redes neuronales y regresi칩n lineal."
      },
      {
        question: "쮺u치les afirmaciones son correctas respecto a la infraestructura global de AWS? (Seleccionar dos)",
        options: [
          "Cada Zona de Disponibilidad (AZ) consiste en uno o m치s centros de datos discretos",
          "Cada Regi칩n de AWS consiste en un m칤nimo de dos Zonas de Disponibilidad (AZ)",
          "Las regiones de AWS est치n ubicadas en el mismo pa칤s para optimizar costos",
          "Las Zonas de Disponibilidad dependen de servidores locales de clientes"
        ],
        answers: [
          "Cada Zona de Disponibilidad (AZ) consiste en uno o m치s centros de datos discretos",
          "Cada Regi칩n de AWS consiste en un m칤nimo de dos Zonas de Disponibilidad (AZ)"
        ],
        multipleCorrect: true,
        explanation: "AWS organiza su infraestructura en Regiones con m칰ltiples Zonas de Disponibilidad (AZ) para garantizar alta disponibilidad y resiliencia."
      },
      {
        question: "쮺u치l es el enfoque m치s eficiente para garantizar que las respuestas de un modelo no contengan informaci칩n confidencial?",
        options: [
          "Aplicar Amazon Bedrock Guardrails",
          "Activar AWS Shield",
          "Habilitar Amazon VPC",
          "Usar AWS CloudTrail"
        ],
        answers: ["Aplicar Amazon Bedrock Guardrails"],
        multipleCorrect: false,
        explanation: "Amazon Bedrock Guardrails permite enmascarar o restringir informaci칩n sensible en las respuestas generadas por modelos de IA."
      },
      {
        question: "쯈u칠 servicio de AWS basado en machine learning ofrece capacidades de b칰squeda unificada?",
        options: ["Amazon Kendra", "Amazon Lex", "Amazon Polly", "Amazon Forecast"],
        answers: ["Amazon Kendra"],
        multipleCorrect: false,
        explanation: "Amazon Kendra es un servicio de b칰squeda basado en machine learning que permite realizar b칰squedas inteligentes en documentos y bases de datos."
      },
      {
        question: "쮺칩mo se llaman las unidades discretas de texto que los modelos de IA procesan?",
        options: ["Tokens", "Embeddings", "Features", "Frames"],
        answers: ["Tokens"],
        multipleCorrect: false,
        explanation: "Los tokens son las unidades m칤nimas de texto que los modelos de lenguaje procesan, como palabras o fragmentos de palabras."
      },
      {
        question: "쮺u치les opciones representan las diferencias clave entre Amazon Q y Amazon Bedrock? (Seleccionar dos)",
        options: [
          "Amazon Q es un asistente de IA generativa que permite crear aplicaciones preempaquetadas de IA generativa, mientras que Amazon Bedrock proporciona un entorno para construir y escalar aplicaciones de IA generativa utilizando un Modelo Fundacional (FM)",
          "Amazon Bedrock permite elegir el Modelo Fundacional subyacente, mientras que Amazon Q no ofrece esta opci칩n",
          "Amazon Q permite a los usuarios personalizar modelos de IA fundacionales sin restricciones",
          "Amazon Bedrock solo permite el uso de modelos propietarios de AWS"
        ],
        answers: [
          "Amazon Q es un asistente de IA generativa que permite crear aplicaciones preempaquetadas de IA generativa, mientras que Amazon Bedrock proporciona un entorno para construir y escalar aplicaciones de IA generativa utilizando un Modelo Fundacional (FM)",
          "Amazon Bedrock permite elegir el Modelo Fundacional subyacente, mientras que Amazon Q no ofrece esta opci칩n"
        ],
        multipleCorrect: true,
        explanation: "Amazon Q proporciona soluciones de IA generativa listas para usar, mientras que Amazon Bedrock permite a los desarrolladores seleccionar y ajustar modelos fundacionales."
      },
      {
        question: "Una empresa est치 implementando un modelo de IA generativa en Amazon Bedrock y necesita reducir los costos de uso. 쯈u칠 enfoque ser칤a el m치s efectivo?",
        options: [
          "Reducir la cantidad de tokens en la entrada",
          "Aumentar el n칰mero de capas del modelo",
          "Habilitar auto-scaling en la infraestructura",
          "Utilizar instancias de GPU m치s grandes"
        ],
        answers: ["Reducir la cantidad de tokens en la entrada"],
        multipleCorrect: false,
        explanation: "Reducir la cantidad de tokens en la entrada disminuye el costo de procesamiento en modelos de IA generativa."
      },
      {
        question: "쯈u칠 afirmaci칩n es correcta sobre los Modelos Fundacionales (FM) en el contexto de la IA generativa?",
        options: [
          "Los FM utilizan aprendizaje auto-supervisado para crear etiquetas a partir de datos de entrada, pero el ajuste fino de un FM es un proceso de aprendizaje supervisado",
          "Los FM solo pueden entrenarse con datos etiquetados",
          "El ajuste fino de un FM siempre requiere millones de datos adicionales",
          "Los FM no pueden ser ajustados despu칠s de su entrenamiento inicial"
        ],
        answers: ["Los FM utilizan aprendizaje auto-supervisado para crear etiquetas a partir de datos de entrada, pero el ajuste fino de un FM es un proceso de aprendizaje supervisado"],
        multipleCorrect: false,
        explanation: "Los Modelos Fundacionales se entrenan de manera auto-supervisada, pero su ajuste fino se realiza mediante aprendizaje supervisado."
      },
      {
        question: "쯈u칠 deber칤a pedir un desarrollador al equipo de investigaci칩n para garantizar que se seleccione el mejor modelo para una aplicaci칩n de predicci칩n de abandono de clientes?",
        options: [
          "Definir el caso de uso de la aplicaci칩n de manera espec칤fica",
          "Usar siempre modelos de deep learning",
          "Elegir el modelo con la menor cantidad de par치metros",
          "Priorizar modelos con mayor complejidad matem치tica"
        ],
        answers: ["Definir el caso de uso de la aplicaci칩n de manera espec칤fica"],
        multipleCorrect: false,
        explanation: "Definir un caso de uso claro ayuda a seleccionar el modelo m치s adecuado para la predicci칩n de abandono de clientes."
      },
      {
        question: "쮺칩mo influye el par치metro de inferencia 'Top P' en la respuesta del modelo en Amazon Bedrock?",
        options: [
          "Influye en el porcentaje de los candidatos m치s probables que el modelo considera para el siguiente token",
          "Determina la cantidad de par치metros del modelo",
          "Controla la tasa de aprendizaje del modelo",
          "Afecta el almacenamiento de los embeddings generados"
        ],
        answers: ["Influye en el porcentaje de los candidatos m치s probables que el modelo considera para el siguiente token"],
        multipleCorrect: false,
        explanation: "El par치metro 'Top P' (nucleus sampling) ajusta el subconjunto de tokens considerados en la generaci칩n de texto."
      },
      {
        question: "쯈u칠 problema espec칤fico est치 tratando de abordar un comit칠 de admisiones detectando el uso de IA generativa en ensayos de aplicaci칩n?",
        options: [
          "Plagio",
          "Consumo excesivo de GPU",
          "Optimizaci칩n de redes neuronales",
          "Reducci칩n de latencia en inferencia"
        ],
        answers: ["Plagio"],
        multipleCorrect: false,
        explanation: "El comit칠 busca evitar el uso de IA generativa para generar ensayos acad칠micos de manera fraudulenta."
      },
      {
        question: "쯈u칠 par치metro de inferencia se recomienda para regular el n칰mero de candidatos m치s probables considerados para la pr칩xima palabra en la salida del modelo?",
        options: ["Top K", "Learning Rate", "Batch Size", "Dropout"],
        answers: ["Top K"],
        multipleCorrect: false,
        explanation: "El par치metro 'Top K' limita el n칰mero de candidatos m치s probables para generar texto, controlando la aleatoriedad."
      },
      {
        question: "쮸 qu칠 fase del proceso de ciencia de datos pertenece el an치lisis de un gran conjunto de datos para identificar patrones y tendencias?",
        options: [
          "An치lisis Exploratorio de Datos (EDA)",
          "Optimizaci칩n de hiperpar치metros",
          "Inferencia en tiempo real",
          "Regularizaci칩n de modelos"
        ],
        answers: ["An치lisis Exploratorio de Datos (EDA)"],
        multipleCorrect: false,
        explanation: "El An치lisis Exploratorio de Datos (EDA) permite descubrir patrones y tendencias en conjuntos de datos sin aplicar modelos a칰n."
      },
      {
        question: "Un chatbot de un Modelo de Lenguaje Extenso (LLM) genera respuestas aparentemente plausibles pero incorrectas. 쮺칩mo se llama este fen칩meno?",
        options: ["Alucinaci칩n", "Overfitting", "Desbalanceo de datos", "Regularizaci칩n"],
        answers: ["Alucinaci칩n"],
        multipleCorrect: false,
        explanation: "La alucinaci칩n ocurre cuando un modelo de IA generativa produce informaci칩n incorrecta pero que parece ver칤dica."
      },
      {
        question: "쯈u칠 servicio de AWS sugiere para implementar soluciones impulsadas por IA para visi칩n por computadora preentrenada y personalizable?",
        options: ["Amazon Rekognition", "Amazon Polly", "Amazon Kendra", "Amazon Forecast"],
        answers: ["Amazon Rekognition"],
        multipleCorrect: false,
        explanation: "Amazon Rekognition permite an치lisis de im치genes y videos con modelos preentrenados y personalizables."
      },
      {
        question: "쮺u치l ser칤a el enfoque m치s efectivo para mejorar la capacidad de un modelo para generalizar en un entorno de producci칩n?",
        options: [
          "Usar hiperpar치metros para ajustar el modelo",
          "Reducir el tama침o del conjunto de datos",
          "Eliminar completamente el preentrenamiento",
          "Forzar sobreajuste en datos de entrenamiento"
        ],
        answers: ["Usar hiperpar치metros para ajustar el modelo"],
        multipleCorrect: false,
        explanation: "El ajuste de hiperpar치metros mejora la capacidad del modelo para generalizar a nuevos datos en producci칩n."
      },
      {
        question: "쯈u칠 diferencia mejor describe los valores de Shapley y los gr치ficos de dependencia parcial (PDP) en el contexto de la interpretabilidad del modelo?",
        options: [
          "Los valores de Shapley proporcionan una explicaci칩n local al cuantificar la contribuci칩n de cada caracter칤stica a la predicci칩n de una instancia espec칤fica, mientras que los PDP proporcionan una explicaci칩n global mostrando el efecto marginal de una caracter칤stica en las predicciones del modelo a trav칠s del conjunto de datos",
          "Los valores de Shapley y los PDP son equivalentes en cuanto a su aplicabilidad",
          "Los PDP permiten entender el impacto exacto de cada caracter칤stica en cada predicci칩n espec칤fica",
          "Los valores de Shapley solo aplican a modelos lineales"
        ],
        answers: [
          "Los valores de Shapley proporcionan una explicaci칩n local al cuantificar la contribuci칩n de cada caracter칤stica a la predicci칩n de una instancia espec칤fica, mientras que los PDP proporcionan una explicaci칩n global mostrando el efecto marginal de una caracter칤stica en las predicciones del modelo a trav칠s del conjunto de datos"
        ],
        multipleCorrect: false,
        explanation: "Los valores de Shapley permiten explicaciones a nivel individual, mientras que los PDP muestran tendencias generales en los datos."
      },
      {
        question: "쮺칩mo define mejor el uso de MLflow con Amazon SageMaker en la gesti칩n de experimentos de aprendizaje autom치tico?",
        options: [
          "Gestionar experimentos de aprendizaje autom치tico",
          "Ejecutar inferencia en tiempo real",
          "Monitorear tr치fico en redes neuronales",
          "Optimizar costos de almacenamiento en S3"
        ],
        answers: ["Gestionar experimentos de aprendizaje autom치tico"],
        multipleCorrect: false,
        explanation: "MLflow en Amazon SageMaker permite gestionar experimentos de aprendizaje autom치tico de forma eficiente."
      },
      {
        question: "쮺칩mo define mejor el uso de MLflow con Amazon SageMaker en la gesti칩n de experimentos de aprendizaje autom치tico?",
        options: [
          "Gestionar experimentos de aprendizaje autom치tico",
          "Ejecutar inferencia en tiempo real",
          "Monitorear tr치fico en redes neuronales",
          "Optimizar costos de almacenamiento en S3"
        ],
        answers: ["Gestionar experimentos de aprendizaje autom치tico"],
        multipleCorrect: false,
        explanation: "MLflow en Amazon SageMaker permite gestionar experimentos de aprendizaje autom치tico de forma eficiente."
      },
      {
        question: "쯈u칠 m칠todo es m치s adecuado para evaluar el rendimiento de un modelo de clasificaci칩n?",
        options: ["Matriz de confusi칩n", "Rendimiento de GPU", "BLEU Score", "Mean Squared Error"],
        answers: ["Matriz de confusi칩n"],
        multipleCorrect: false,
        explanation: "La matriz de confusi칩n es una herramienta fundamental para evaluar modelos de clasificaci칩n."
      },
      {
        question: "쮺칩mo funcionan los modelos Transformer?",
        options: [
          "Utilizan un mecanismo de auto-atenci칩n e implementan embeddings contextuales",
          "Usan solo redes neuronales recurrentes",
          "Dependen exclusivamente de modelos lineales",
          "Funcionan con reglas predefinidas sin entrenamiento"
        ],
        answers: ["Utilizan un mecanismo de auto-atenci칩n e implementan embeddings contextuales"],
        multipleCorrect: false,
        explanation: "Los modelos Transformer se basan en la auto-atenci칩n y embeddings contextuales para comprender relaciones entre palabras."
      },
      {
        question: "쯈u칠 recomiendas para crear una aplicaci칩n generativa de IA en Amazon Bedrock para optimizar el monitoreo de niveles de inventario y datos de ventas?",
        options: ["Agents for Amazon Bedrock", "Amazon Rekognition", "Amazon Polly", "Amazon Redshift"],
        answers: ["Agents for Amazon Bedrock"],
        multipleCorrect: false,
        explanation: "Agents for Amazon Bedrock permite construir aplicaciones generativas optimizadas para diversas tareas empresariales."
      },
      {
        question: "쯈u칠 servicio de AWS est치 dise침ado espec칤ficamente para proporcionar informaci칩n sobre las predicciones del modelo explicando c칩mo las caracter칤sticas de entrada contribuyen a la salida final?",
        options: ["Amazon SageMaker Clarify", "Amazon Bedrock", "Amazon Kendra", "AWS Shield"],
        answers: ["Amazon SageMaker Clarify"],
        multipleCorrect: false,
        explanation: "Amazon SageMaker Clarify ayuda a interpretar modelos de ML y explicar su razonamiento."
      },
      {
        question: "쯈u칠 soluci칩n recomiendas para implementar soporte gestionado en Amazon Bedrock para un flujo de trabajo de Generaci칩n Aumentada por Recuperaci칩n (RAG)?",
        options: ["Knowledge Bases for Amazon Bedrock", "Amazon Kendra", "Amazon Comprehend", "Amazon Rekognition"],
        answers: ["Knowledge Bases for Amazon Bedrock"],
        multipleCorrect: false,
        explanation: "Knowledge Bases for Amazon Bedrock permite implementar flujos de trabajo optimizados para RAG."
      },
      {
        question: "쯈u칠 tipo de sesgo es m치s probable que cause un modelo de IA que identifica desproporcionadamente individuos de un grupo 칠tnico espec칤fico debido a un desequilibrio en los datos de entrenamiento?",
        options: ["Sesgo de muestreo (Sampling bias)", "Sesgo de selecci칩n (Selection bias)", "Sobreajuste (Overfitting)", "Submuestreo (Undersampling)"],
        answers: ["Sesgo de muestreo (Sampling bias)"],
        multipleCorrect: false,
        explanation: "El sesgo de muestreo ocurre cuando los datos de entrenamiento no representan adecuadamente a todos los grupos de poblaci칩n."
      },
      {
        question: "쮺칩mo se llama el concepto que define la cantidad m치xima de texto o caracteres que un modelo de IA puede procesar a la vez?",
        options: ["Ventana de contexto (Context window)", "Tasa de aprendizaje", "Embedding dimensionality", "Batch size"],
        answers: ["Ventana de contexto (Context window)"],
        multipleCorrect: false,
        explanation: "La ventana de contexto limita la cantidad de tokens que un modelo puede procesar simult치neamente."
      },
      {
        question: "쯈u칠 servicios de AWS recomiendas para desarrollar soluciones basadas en LLM en este entorno? (Seleccionar dos)",
        options: ["Amazon SageMaker JumpStart", "Amazon Bedrock", "AWS Lambda", "Amazon Aurora"],
        answers: ["Amazon SageMaker JumpStart", "Amazon Bedrock"],
        multipleCorrect: true,
        explanation: "Amazon SageMaker JumpStart y Amazon Bedrock proporcionan herramientas optimizadas para el desarrollo de aplicaciones basadas en LLM."
      },
      {
        question: "쯈u칠 t칠cnicas de IA generativa se usan en el flujo de trabajo de la aplicaci칩n web de Amazon Q? (Seleccionar dos)",
        options: [
          "Large Language Model (LLM)",
          "Retrieval-Augmented Generation (RAG)",
          "Regresi칩n log칤stica",
          "Transformers sin embeddings"
        ],
        answers: ["Large Language Model (LLM)", "Retrieval-Augmented Generation (RAG)"],
        multipleCorrect: true,
        explanation: "Amazon Q usa modelos LLM y RAG para mejorar la generaci칩n y recuperaci칩n de informaci칩n."
      },
      {
        question: "쯈u칠 servicios de AWS recomendar칤as para realizar an치lisis de sentimientos en llamadas de audio de servicio al cliente?",
        options: ["Amazon Transcribe", "Amazon Comprehend", "Amazon Rekognition", "AWS Shield"],
        answers: ["Amazon Transcribe", "Amazon Comprehend"],
        multipleCorrect: true,
        explanation: "Amazon Transcribe convierte audio en texto, y Amazon Comprehend analiza los sentimientos en el texto generado."
      },
      {
        question: "쯈u칠 modelo de precios ser칤a m치s adecuado para una empresa que busca flexibilidad y no est치 segura de la frecuencia con la que usar치 Amazon Bedrock?",
        options: [
          "On-demand pricing",
          "Reservar capacidad fija",
          "Comprar instancias dedicadas",
          "Licencia perpetua"
        ],
        answers: ["On-demand pricing"],
        multipleCorrect: false,
        explanation: "El modelo de pago por uso (on-demand) es ideal para empresas con uso variable de Amazon Bedrock."
      },
      {
        question: "쯈u칠 enfoque ser칤a m치s adecuado para ajustar finamente un modelo fundacional en Amazon Bedrock para el an치lisis de texto m칠dico?",
        options: [
          "Provisioned Throughput mode",
          "Fine-tuning on demand",
          "Data augmentation",
          "Self-supervised learning"
        ],
        answers: ["Provisioned Throughput mode"],
        multipleCorrect: false,
        explanation: "Provisioned Throughput mode permite reservar una capacidad espec칤fica para la inferencia del modelo en Amazon Bedrock."
      },
      {
        question: "쯈u칠 recomendar칤as al departamento de marketing de una empresa de medios que quiere usar Amazon Bedrock para crear guiones creativos para una pr칩xima campa침a publicitaria?",
        options: [
          "Usar una temperatura m치s alta para obtener respuestas m치s creativas",
          "Reducir el tama침o del modelo para mejorar la eficiencia",
          "Desactivar la generaci칩n de tokens repetitivos",
          "Configurar restricciones de longitud de texto"
        ],
        answers: ["Usar una temperatura m치s alta para obtener respuestas m치s creativas"],
        multipleCorrect: false,
        explanation: "Aumentar la temperatura en Amazon Bedrock permite generar respuestas m치s creativas y variadas."
      },
      {
        question: "Una empresa minorista tiene cat치logos de productos en formato PDF y busca proporcionar respuestas relevantes y actualizadas a consultas de clientes a trav칠s de su chatbot impulsado por Amazon Bedrock. 쯈u칠 enfoque representa la soluci칩n m치s rentable?",
        options: [
          "Utilizar un sistema de Generaci칩n Aumentada por Recuperaci칩n (RAG) indexando los cat치logos PDF",
          "Entrenar un modelo personalizado con todos los productos",
          "Generar embeddings de todos los productos en una base de datos relacional",
          "Aumentar la memoria del chatbot para almacenar m치s respuestas predefinidas"
        ],
        answers: ["Utilizar un sistema de Generaci칩n Aumentada por Recuperaci칩n (RAG) indexando los cat치logos PDF"],
        multipleCorrect: false,
        explanation: "RAG permite a los chatbots acceder a informaci칩n actualizada sin necesidad de reentrenar el modelo."
      },
      {
        question: "El departamento de marketing de una empresa minorista quiere excluir nombres de marcas competidoras o temas sensibles del contenido producido mediante prompts de IA generativa. 쯈u칠 t칠cnica de prompting representa este caso de uso?",
        options: [
          "Negative prompting",
          "Few-shot prompting",
          "Temperature control",
          "Data augmentation"
        ],
        answers: ["Negative prompting"],
        multipleCorrect: false,
        explanation: "Negative prompting permite restringir palabras o temas no deseados en las respuestas generadas."
      },
      {
        question: "쮺u치l es una diferencia clave entre Foundation Models (FM) y Large Language Models (LLM) en el contexto de la IA generativa?",
        options: [
          "Foundation Models sirven como base para diversas aplicaciones de IA, mientras que los LLM est치n especializados en comprensi칩n y generaci칩n de lenguaje humano",
          "Los FM son modelos m치s peque침os que los LLM",
          "LLM solo se pueden entrenar en Amazon Bedrock",
          "Los FM no pueden ser ajustados para tareas espec칤ficas"
        ],
        answers: [
          "Foundation Models sirven como base para diversas aplicaciones de IA, mientras que los LLM est치n especializados en comprensi칩n y generaci칩n de lenguaje humano"
        ],
        multipleCorrect: false,
        explanation: "Los FM proporcionan capacidades amplias de IA, mientras que los LLM se enfocan en procesamiento de lenguaje natural."
      },
      {
        question: "쮺u치l de las siguientes opciones resume mejor la diferencia entre inferencia y evaluaci칩n de modelos en IA generativa?",
        options: [
          "La evaluaci칩n compara modelos para determinar el mejor para un caso de uso, mientras que la inferencia es el proceso de generar respuestas a partir de una entrada",
          "La inferencia siempre es m치s costosa que la evaluaci칩n",
          "La evaluaci칩n se realiza solo despu칠s de entrenar el modelo",
          "La inferencia mejora el modelo sin necesidad de reentrenarlo"
        ],
        answers: [
          "La evaluaci칩n compara modelos para determinar el mejor para un caso de uso, mientras que la inferencia es el proceso de generar respuestas a partir de una entrada"
        ],
        multipleCorrect: false,
        explanation: "Evaluar un modelo ayuda a seleccionar el m치s adecuado, mientras que la inferencia es el uso del modelo para generar respuestas."
      },
      {
        question: "쯈u칠 soluci칩n de base de datos ser칤a m치s apropiada para una empresa que usa Amazon Bedrock y RAG para mejorar el soporte al cliente?",
        options: [
          "Amazon OpenSearch Service",
          "Amazon DynamoDB",
          "Amazon S3",
          "Amazon Redshift"
        ],
        answers: ["Amazon OpenSearch Service"],
        multipleCorrect: false,
        explanation: "Amazon OpenSearch Service es ideal para b칰squedas r치pidas y recuperaci칩n de informaci칩n en sistemas de soporte con RAG."
      },
      {
        question: "Una empresa ha desarrollado un modelo generador de im치genes basado en IA, pero ha notado que produce resultados sesgados debido a datos desbalanceados. 쮺u치l ser칤a la estrategia m치s adecuada para abordar este problema?",
        options: [
          "Aumentar los datos para incluir instancias de grupos subrepresentados",
          "Reducir el tama침o del conjunto de datos",
          "Eliminar completamente las im치genes problem치ticas",
          "Usar un modelo de menor capacidad"
        ],
        answers: ["Aumentar los datos para incluir instancias de grupos subrepresentados"],
        multipleCorrect: false,
        explanation: "El aumento de datos con ejemplos representativos ayuda a mitigar sesgos en los modelos generativos."
      },
      {
        question: "쯈u칠 servicio de AWS potencia las funcionalidades principales de Amazon Q Developer?",
        options: ["Amazon Bedrock", "Amazon SageMaker", "AWS Lambda", "Amazon Kendra"],
        answers: ["Amazon Bedrock"],
        multipleCorrect: false,
        explanation: "Amazon Q Developer se basa en Amazon Bedrock para generar respuestas y recomendaciones avanzadas."
      },
      {
        question: "Una empresa de comercio electr칩nico usa un chatbot con Amazon Bedrock y desea que mejore continuamente bas치ndose en interacciones con clientes en tiempo real. 쯈u칠 enfoque ser칤a el m치s adecuado?",
        options: [
          "Aplicar aprendizaje por refuerzo (Reinforcement Learning)",
          "Reducir el tama침o del modelo",
          "Configurar respuestas predefinidas",
          "Entrenar un modelo desde cero cada semana"
        ],
        answers: ["Aplicar aprendizaje por refuerzo (Reinforcement Learning)"],
        multipleCorrect: false,
        explanation: "El aprendizaje por refuerzo permite mejorar el chatbot a partir de interacciones reales y retroalimentaci칩n de los usuarios."
      },
      {
        question: "쯈u칠 servicio de Amazon SageMaker puede ayudar a monitorear y gestionar modelos implementados en endpoints?",
        options: ["Amazon SageMaker Model Dashboard", "Amazon S3", "Amazon Kendra", "AWS Glue"],
        answers: ["Amazon SageMaker Model Dashboard"],
        multipleCorrect: false,
        explanation: "Amazon SageMaker Model Dashboard proporciona herramientas para monitorear y gestionar modelos en producci칩n."
      },
      {
        question: "쯈u칠 enfoque recomendar칤as para mejorar la precisi칩n de los modelos de machine learning de una empresa?",
        options: ["Incrementar el n칰mero de 칠pocas (epochs)", "Reducir la cantidad de datos de entrenamiento", "Aplicar solo regularizaci칩n", "Eliminar hiperpar치metros"],
        answers: ["Incrementar el n칰mero de 칠pocas (epochs)"],
        multipleCorrect: false,
        explanation: "Incrementar las 칠pocas permite que el modelo aprenda mejor los patrones de los datos."
      },
      {
        question: "Una empresa est치 utilizando un Modelo de Lenguaje Extenso (LLM) en Amazon Bedrock y quiere regular la creatividad de las respuestas del modelo. 쮺u치l de los siguientes par치metros de inferencia recomendar칤as para el caso de uso dado?",
        options: ["Temperature", "Batch Size", "Learning Rate", "Dropout"],
        answers: ["Temperature"],
        multipleCorrect: false,
        explanation: "El par치metro Temperature controla la creatividad del modelo ajustando la aleatoriedad en la generaci칩n de texto."
      },
      {
        question: "Una empresa de servicios financieros est치 desarrollando un modelo de Deep Learning para detectar transacciones fraudulentas en tiempo real. 쮺칩mo operan las redes neuronales en este contexto?",
        options: [
          "Las redes neuronales operan almacenando todos los posibles resultados y seleccionando el m치s apropiado para cada entrada",
          "Las redes neuronales aprenden a realizar tareas al ser programadas expl칤citamente con reglas para cada tarea",
          "Las redes neuronales dependen 칰nicamente de f칩rmulas matem치ticas predefinidas y no aprenden de los datos",
          "Las redes neuronales consisten en capas de nodos (neuronas) que procesan datos de entrada y ajustan pesos basados en patrones detectados"
        ],
        answers: ["Las redes neuronales consisten en capas de nodos (neuronas) que procesan datos de entrada y ajustan pesos basados en patrones detectados"],
        multipleCorrect: false,
        explanation: "Las redes neuronales utilizan pesos ajustables y m칰ltiples capas para aprender patrones en los datos."
      },
      {
        question: "Una empresa de medios est치 desarrollando aplicaciones de IA generativa en AWS. 쯈u칠 estrategia de seguridad es clave para proteger los modelos de ataques adversariales?",
        options: [
          "Aplicar m칰ltiples capas de medidas de seguridad, incluyendo la validaci칩n de entradas",
          "Reducir el tama침o del modelo para disminuir el impacto de posibles ataques",
          "Limitar el acceso a los modelos solo a usuarios internos",
          "Configurar modelos en entornos de baja latencia para minimizar riesgos"
        ],
        answers: ["Aplicar m칰ltiples capas de medidas de seguridad, incluyendo la validaci칩n de entradas"],
        multipleCorrect: false,
        explanation: "La validaci칩n de entradas y m칰ltiples capas de seguridad protegen los modelos de ataques adversariales."
      },
      {
        question: "Una empresa tecnol칩gica est치 considerando usar Amazon Web Services (AWS). 쮼n qu칠 categor칤a de servicio en la nube encaja AWS?",
        options: ["Infraestructura como Servicio (IaaS)", "Plataforma como Servicio (PaaS)", "Software como Servicio (SaaS)", "Funci칩n como Servicio (FaaS)"],
        answers: ["Infraestructura como Servicio (IaaS)"],
        multipleCorrect: false,
        explanation: "AWS ofrece Infraestructura como Servicio (IaaS), proporcionando recursos de c칩mputo, almacenamiento y redes."
      },
      {
        question: "Una empresa minorista est치 iniciando un proyecto de aprendizaje autom치tico. 쮺u치l es el mayor desaf칤o que puede enfrentar?",
        options: [
          "Dificultad para recopilar y preparar datos de alta calidad para entrenar modelos",
          "Escasez de herramientas de aprendizaje autom치tico en AWS",
          "Limitaciones en la capacidad de c칩mputo para entrenar modelos",
          "Falta de algoritmos eficientes para el aprendizaje autom치tico"
        ],
        answers: ["Dificultad para recopilar y preparar datos de alta calidad para entrenar modelos"],
        multipleCorrect: false,
        explanation: "La recopilaci칩n y preparaci칩n de datos de alta calidad es un desaf칤o cr칤tico para el 칠xito de los modelos de aprendizaje autom치tico."
      },
      {
        question: "Una empresa de atenci칩n m칠dica est치 evaluando el uso de Modelos Fundamentales (FMs). 쮺u치l de las siguientes afirmaciones es correcta?",
        options: [
          "Los FMs usan conjuntos de datos de entrenamiento no etiquetados para aprendizaje autosupervisado",
          "Los FMs requieren datos altamente estructurados para ser entrenados",
          "Los FMs solo pueden ser ajustados con aprendizaje supervisado",
          "Los FMs est치n limitados a tareas de procesamiento de texto"
        ],
        answers: ["Los FMs usan conjuntos de datos de entrenamiento no etiquetados para aprendizaje autosupervisado"],
        multipleCorrect: false,
        explanation: "Los Modelos Fundamentales (FMs) utilizan aprendizaje autosupervisado en grandes vol칰menes de datos no etiquetados."
      },
      {
        question: "Una empresa minorista est치 desarrollando un modelo de aprendizaje autom치tico para predecir la p칠rdida de clientes. 쮺u치l es una afirmaci칩n correcta sobre los conjuntos de datos utilizados?",
        options: [
          "El conjunto de prueba se utiliza para determinar qu칠 tan bien generaliza el modelo",
          "Los conjuntos de validaci칩n son opcionales",
          "Los datos de entrenamiento deben incluir 칰nicamente datos futuros",
          "El conjunto de prueba debe ser id칠ntico al conjunto de entrenamiento"
        ],
        answers: ["El conjunto de prueba se utiliza para determinar qu칠 tan bien generaliza el modelo", "Los conjuntos de validaci칩n son opcionales"],
        multipleCorrect: true,
        explanation: "El conjunto de prueba eval칰a la generalizaci칩n del modelo, mientras que los conjuntos de validaci칩n ayudan a optimizar hiperpar치metros."
      },
      {
        question: "Una empresa de atenci칩n m칠dica est치 considerando migrar su infraestructura local a AWS Cloud. 쮺u치l es una afirmaci칩n correcta sobre la computaci칩n en la nube?",
        options: [
          "La computaci칩n en la nube se refiere a la entrega bajo demanda de recursos y aplicaciones de TI a trav칠s de internet",
          "Los entornos en la nube requieren hardware dedicado en las instalaciones del cliente",
          "Las aplicaciones en la nube solo pueden ejecutarse en centros de datos propietarios",
          "AWS no admite almacenamiento de datos en la nube"
        ],
        answers: ["La computaci칩n en la nube se refiere a la entrega bajo demanda de recursos y aplicaciones de TI a trav칠s de internet"],
        multipleCorrect: false,
        explanation: "La computaci칩n en la nube permite acceder a recursos bajo demanda sin necesidad de hardware local."
      },
      {
        question: "Una empresa de atenci칩n m칠dica est치 implementando modelos de IA usando Amazon SageMaker. 쯈u칠 afirmaci칩n es correcta sobre las tarjetas de modelos?",
        options: [
          "Las tarjetas de modelos de SageMaker incluyen informaci칩n sobre el modelo, como su uso previsto y limitaciones",
          "Las tarjetas de modelos de SageMaker solo contienen metadatos b치sicos",
          "Los modelos entrenados en SageMaker no requieren tarjetas de modelos",
          "Las tarjetas de modelos solo est치n disponibles para modelos de terceros"
        ],
        answers: ["Las tarjetas de modelos de SageMaker incluyen informaci칩n sobre el modelo, como su uso previsto y limitaciones"],
        multipleCorrect: false,
        explanation: "Las tarjetas de modelos en SageMaker proporcionan documentaci칩n sobre el uso y limitaciones de cada modelo."
      },
      {
        question: "Una empresa de servicios financieros est치 implementando modelos de aprendizaje autom치tico para automatizar la detecci칩n de fraudes. 쯈u칠 servicios de AWS pueden ayudar en este caso?",
        options: [
          "Amazon SageMaker Model Monitor",
          "Amazon Augmented AI (Amazon A2I)",
          "Amazon Rekognition",
          "Amazon Polly"
        ],
        answers: ["Amazon SageMaker Model Monitor", "Amazon Augmented AI (Amazon A2I)"],
        multipleCorrect: true,
        explanation: "Model Monitor permite supervisar modelos en producci칩n, mientras que A2I ayuda a incorporar revisi칩n humana cuando es necesario."
      },
      {
        question: "Una empresa est치 utilizando Amazon Bedrock y desea establecer un l칤mite m치ximo en el n칰mero de tokens devueltos en la respuesta del modelo. 쯈u칠 par치metro de inferencia debe ajustar?",
        options: ["Longitud de la respuesta (Response length)", "Temperature", "Top-K", "Batch Size"],
        answers: ["Longitud de la respuesta (Response length)"],
        multipleCorrect: false,
        explanation: "El par치metro 'Longitud de la respuesta' controla la cantidad m치xima de tokens generados por el modelo."
      },
      {
        question: "Una empresa de log칤stica est치 explorando el uso de modelos de aprendizaje autom치tico para optimizar las operaciones de la cadena de suministro. 쯈u칠 afirmaci칩n es correcta sobre estos modelos?",
        options: [
          "Los modelos de aprendizaje autom치tico pueden ser deterministas, probabil칤sticos o una combinaci칩n de ambos.",
          "Solo existen modelos de aprendizaje autom치tico deterministas.",
          "Los modelos probabil칤sticos no se utilizan en la optimizaci칩n de cadenas de suministro.",
          "El aprendizaje autom치tico no puede aplicarse a la log칤stica."
        ],
        answers: ["Los modelos de aprendizaje autom치tico pueden ser deterministas, probabil칤sticos o una combinaci칩n de ambos."],
        multipleCorrect: false,
        explanation: "Los modelos pueden generar predicciones deterministas o probabil칤sticas dependiendo del enfoque utilizado."
      },
      {
        question: "Una firma legal busca implementar una soluci칩n de IA para generar respuestas detalladas y precisas a las consultas de los clientes. 쯈u칠 soluciones pueden ayudar?",
        options: [
          "Chatbot para consultas m칠dicas",
          "Chatbot para servicio al cliente",
          "Amazon Rekognition",
          "Amazon Polly"
        ],
        answers: ["Chatbot para servicio al cliente"],
        multipleCorrect: false,
        explanation: "Un chatbot bien entrenado puede ayudar a responder consultas legales bas치ndose en documentos preexistentes."
      },
      {
        question: "Una empresa tecnol칩gica est치 desarrollando una soluci칩n impulsada por IA y necesita dise침ar prompts efectivos para su modelo generativo. 쯈u칠 t칠cnica de prompting es la m치s adecuada?",
        options: [
          "Encadenamiento de pensamiento (Chain-of-thought prompting)",
          "Temperature",
          "Data Augmentation",
          "Aprendizaje Supervisado"
        ],
        answers: ["Encadenamiento de pensamiento (Chain-of-thought prompting)"],
        multipleCorrect: false,
        explanation: "El encadenamiento de pensamiento ayuda a los modelos generativos a generar respuestas m치s estructuradas y razonadas."
      },
      {
        question: "Una empresa de atenci칩n m칠dica est치 construyendo m칰ltiples modelos de aprendizaje autom치tico usando Amazon SageMaker. 쯈u칠 servicio de AWS puede ayudar a administrar estos modelos?",
        options: [
          "Amazon SageMaker Model Dashboard",
          "Amazon OpenSearch",
          "Amazon DynamoDB",
          "AWS Lambda"
        ],
        answers: ["Amazon SageMaker Model Dashboard"],
        multipleCorrect: false,
        explanation: "SageMaker Model Dashboard permite monitorear y gestionar m칰ltiples modelos desplegados."
      },
      {
        question: "Una empresa minorista est치 explorando soluciones avanzadas de IA para mejorar la experiencia del cliente al integrar tanto datos visuales como textuales. 쯈u칠 tipo de modelo es m치s adecuado?",
        options: [
          "Un modelo multimodal puede aceptar una combinaci칩n de tipos de entrada como audio/texto y crear una combinaci칩n de tipos de salida como video/imagen.",
          "Un modelo supervisado con datos tabulares exclusivamente",
          "Un modelo basado en regresi칩n lineal",
          "Un modelo basado en clustering de datos"
        ],
        answers: [
          "Un modelo multimodal puede aceptar una combinaci칩n de tipos de entrada como audio/texto y crear una combinaci칩n de tipos de salida como video/imagen."
        ],
        multipleCorrect: false,
        explanation: "Los modelos multimodales pueden procesar m칰ltiples tipos de datos simult치neamente."
      },
      {
        question: "Una empresa minorista quiere permitir a sus analistas de negocio aprovechar el aprendizaje autom치tico sin necesidad de habilidades extensivas de codificaci칩n. 쯈u칠 servicio de AWS es m치s adecuado?",
        options: ["Amazon SageMaker Canvas", "Amazon Rekognition", "Amazon Kendra", "AWS Glue"],
        answers: ["Amazon SageMaker Canvas"],
        multipleCorrect: false,
        explanation: "SageMaker Canvas permite construir modelos de aprendizaje autom치tico sin necesidad de escribir c칩digo."
      },
      {
        question: "Una empresa de servicios financieros est치 implementando modelos de IA para evaluar el riesgo crediticio. 쮺u치l es la diferencia entre interpretabilidad y explicabilidad?",
        options: [
          "La interpretabilidad consiste en comprender los mecanismos internos de un modelo de aprendizaje autom치tico, mientras que la explicabilidad se centra en proporcionar razones comprensibles para las predicciones y comportamientos del modelo a las partes interesadas.",
          "Interpretabilidad y explicabilidad son t칠rminos intercambiables.",
          "La explicabilidad es m치s importante que la interpretabilidad en todos los casos.",
          "Un modelo interpretable nunca requiere explicabilidad adicional."
        ],
        answers: [
          "La interpretabilidad consiste en comprender los mecanismos internos de un modelo de aprendizaje autom치tico, mientras que la explicabilidad se centra en proporcionar razones comprensibles para las predicciones y comportamientos del modelo a las partes interesadas."
        ],
        multipleCorrect: false,
        explanation: "La interpretabilidad permite analizar c칩mo funciona un modelo, mientras que la explicabilidad ayuda a comunicar sus decisiones."
      },
      {
        question: "Una empresa minorista est치 construyendo un modelo de aprendizaje autom치tico para predecir la demanda de sus productos. 쮺u치l es la diferencia entre sobreajuste y subajuste?",
        options: [
          "El sobreajuste ocurre cuando un modelo funciona bien con los datos de entrenamiento pero mal con datos nuevos, mientras que el subajuste ocurre cuando un modelo funciona mal tanto con los datos de entrenamiento como con los nuevos.",
          "El sobreajuste siempre es preferible al subajuste.",
          "El subajuste significa que el modelo es demasiado complejo.",
          "El sobreajuste indica que el modelo no ha aprendido lo suficiente."
        ],
        answers: [
          "El sobreajuste ocurre cuando un modelo funciona bien con los datos de entrenamiento pero mal con datos nuevos, mientras que el subajuste ocurre cuando un modelo funciona mal tanto con los datos de entrenamiento como con los nuevos."
        ],
        multipleCorrect: false,
        explanation: "El sobreajuste indica que el modelo se ha especializado demasiado en los datos de entrenamiento y no generaliza bien a nuevos datos."
      },
       {
        question: "Una empresa de servicios financieros est치 implementando modelos de aprendizaje autom치tico para automatizar la detecci칩n de fraudes. 쯈u칠 servicios de AWS pueden ayudar en este caso?",
        options: [
          "Amazon SageMaker Model Monitor",
          "Amazon Augmented AI (Amazon A2I)",
          "Amazon Rekognition",
          "Amazon Polly"
        ],
        answers: ["Amazon SageMaker Model Monitor", "Amazon Augmented AI (Amazon A2I)"],
        multipleCorrect: true,
        explanation: "Model Monitor permite supervisar modelos en producci칩n, mientras que A2I ayuda a incorporar revisi칩n humana cuando es necesario."
      },
      {
        question: "Una empresa est치 utilizando Amazon Bedrock y desea establecer un l칤mite m치ximo en el n칰mero de tokens devueltos en la respuesta del modelo. 쯈u칠 par치metro de inferencia debe ajustar?",
        options: ["Longitud de la respuesta (Response length)", "Temperature", "Top-K", "Batch Size"],
        answers: ["Longitud de la respuesta (Response length)"],
        multipleCorrect: false,
        explanation: "El par치metro 'Longitud de la respuesta' controla la cantidad m치xima de tokens generados por el modelo."
      },
      {
        question: "Una empresa de log칤stica est치 explorando el uso de modelos de aprendizaje autom치tico para optimizar las operaciones de la cadena de suministro. 쯈u칠 afirmaci칩n es correcta sobre estos modelos?",
        options: [
          "Los modelos de aprendizaje autom치tico pueden ser deterministas, probabil칤sticos o una combinaci칩n de ambos.",
          "Solo existen modelos de aprendizaje autom치tico deterministas.",
          "Los modelos probabil칤sticos no se utilizan en la optimizaci칩n de cadenas de suministro.",
          "El aprendizaje autom치tico no puede aplicarse a la log칤stica."
        ],
        answers: ["Los modelos de aprendizaje autom치tico pueden ser deterministas, probabil칤sticos o una combinaci칩n de ambos."],
        multipleCorrect: false,
        explanation: "Los modelos pueden generar predicciones deterministas o probabil칤sticas dependiendo del enfoque utilizado."
      },
      {
        question: "Una firma legal busca implementar una soluci칩n de IA para generar respuestas detalladas y precisas a las consultas de los clientes. 쯈u칠 soluciones pueden ayudar?",
        options: [
          "Chatbot para consultas m칠dicas",
          "Chatbot para servicio al cliente",
          "Amazon Rekognition",
          "Amazon Polly"
        ],
        answers: ["Chatbot para servicio al cliente"],
        multipleCorrect: false,
        explanation: "Un chatbot bien entrenado puede ayudar a responder consultas legales bas치ndose en documentos preexistentes."
      },
      {
        question: "Una empresa tecnol칩gica est치 desarrollando una soluci칩n impulsada por IA y necesita dise침ar prompts efectivos para su modelo generativo. 쯈u칠 t칠cnica de prompting es la m치s adecuada?",
        options: [
          "Encadenamiento de pensamiento (Chain-of-thought prompting)",
          "Temperature",
          "Data Augmentation",
          "Aprendizaje Supervisado"
        ],
        answers: ["Encadenamiento de pensamiento (Chain-of-thought prompting)"],
        multipleCorrect: false,
        explanation: "El encadenamiento de pensamiento ayuda a los modelos generativos a generar respuestas m치s estructuradas y razonadas."
      },
      {
        question: "Una empresa de atenci칩n m칠dica est치 construyendo m칰ltiples modelos de aprendizaje autom치tico usando Amazon SageMaker. 쯈u칠 servicio de AWS puede ayudar a administrar estos modelos?",
        options: [
          "Amazon SageMaker Model Dashboard",
          "Amazon OpenSearch",
          "Amazon DynamoDB",
          "AWS Lambda"
        ],
        answers: ["Amazon SageMaker Model Dashboard"],
        multipleCorrect: false,
        explanation: "SageMaker Model Dashboard permite monitorear y gestionar m칰ltiples modelos desplegados."
      },
      {
        question: "Una empresa minorista est치 explorando soluciones avanzadas de IA para mejorar la experiencia del cliente al integrar tanto datos visuales como textuales. 쯈u칠 tipo de modelo es m치s adecuado?",
        options: [
          "Un modelo multimodal puede aceptar una combinaci칩n de tipos de entrada como audio/texto y crear una combinaci칩n de tipos de salida como video/imagen.",
          "Un modelo supervisado con datos tabulares exclusivamente",
          "Un modelo basado en regresi칩n lineal",
          "Un modelo basado en clustering de datos"
        ],
        answers: [
          "Un modelo multimodal puede aceptar una combinaci칩n de tipos de entrada como audio/texto y crear una combinaci칩n de tipos de salida como video/imagen."
        ],
        multipleCorrect: false,
        explanation: "Los modelos multimodales pueden procesar m칰ltiples tipos de datos simult치neamente."
      },
      {
        question: "Una empresa minorista quiere permitir a sus analistas de negocio aprovechar el aprendizaje autom치tico sin necesidad de habilidades extensivas de codificaci칩n. 쯈u칠 servicio de AWS es m치s adecuado?",
        options: ["Amazon SageMaker Canvas", "Amazon Rekognition", "Amazon Kendra", "AWS Glue"],
        answers: ["Amazon SageMaker Canvas"],
        multipleCorrect: false,
        explanation: "SageMaker Canvas permite construir modelos de aprendizaje autom치tico sin necesidad de escribir c칩digo."
      },
      {
        question: "Una empresa de servicios financieros est치 implementando modelos de IA para evaluar el riesgo crediticio. 쮺u치l es la diferencia entre interpretabilidad y explicabilidad?",
        options: [
          "La interpretabilidad consiste en comprender los mecanismos internos de un modelo de aprendizaje autom치tico, mientras que la explicabilidad se centra en proporcionar razones comprensibles para las predicciones y comportamientos del modelo a las partes interesadas.",
          "Interpretabilidad y explicabilidad son t칠rminos intercambiables.",
          "La explicabilidad es m치s importante que la interpretabilidad en todos los casos.",
          "Un modelo interpretable nunca requiere explicabilidad adicional."
        ],
        answers: [
          "La interpretabilidad consiste en comprender los mecanismos internos de un modelo de aprendizaje autom치tico, mientras que la explicabilidad se centra en proporcionar razones comprensibles para las predicciones y comportamientos del modelo a las partes interesadas."
        ],
        multipleCorrect: false,
        explanation: "La interpretabilidad permite analizar c칩mo funciona un modelo, mientras que la explicabilidad ayuda a comunicar sus decisiones."
      },
      {
        question: "Una empresa minorista est치 construyendo un modelo de aprendizaje autom치tico para predecir la demanda de sus productos. 쮺u치l es la diferencia entre sobreajuste y subajuste?",
        options: [
          "El sobreajuste ocurre cuando un modelo funciona bien con los datos de entrenamiento pero mal con datos nuevos, mientras que el subajuste ocurre cuando un modelo funciona mal tanto con los datos de entrenamiento como con los nuevos.",
          "El sobreajuste siempre es preferible al subajuste.",
          "El subajuste significa que el modelo es demasiado complejo.",
          "El sobreajuste indica que el modelo no ha aprendido lo suficiente."
        ],
        answers: [
          "El sobreajuste ocurre cuando un modelo funciona bien con los datos de entrenamiento pero mal con datos nuevos, mientras que el subajuste ocurre cuando un modelo funciona mal tanto con los datos de entrenamiento como con los nuevos."
        ],
        multipleCorrect: false,
        explanation: "El sobreajuste indica que el modelo se ha especializado demasiado en los datos de entrenamiento y no generaliza bien a nuevos datos."
      },
      {
        question: "Una empresa global de comercio electr칩nico est치 aprovechando un Modelo Fundacional (FM) para mejorar su motor de recomendaciones de productos. 쮺u치l de las siguientes opciones es correcta con respecto a las t칠cnicas utilizadas para mejorar el rendimiento de un Modelo Fundacional (FM)?",
        options: [
          "El ajuste fino cambia los pesos del FM mientras que la generaci칩n aumentada por recuperaci칩n (RAG) no cambia los pesos del FM.",
          "RAG cambia los pesos del FM mientras que el ajuste fino no los modifica.",
          "Ambos m칠todos requieren reentrenamiento del modelo desde cero.",
          "Solo los modelos supervisados pueden beneficiarse de RAG."
        ],
        answers: ["El ajuste fino cambia los pesos del FM mientras que la generaci칩n aumentada por recuperaci칩n (RAG) no cambia los pesos del FM."],
        multipleCorrect: false,
        explanation: "El ajuste fino optimiza los pesos internos del modelo, mientras que RAG mejora las respuestas sin modificar el modelo base."
      },
      {
        question: "Una startup de atenci칩n m칠dica est치 desarrollando un modelo de aprendizaje autom치tico y ha detectado signos de sobreajuste. 쮺칩mo se puede prevenir el sobreajuste del modelo en aprendizaje autom치tico?",
        options: [
          "Usando t칠cnicas como validaci칩n cruzada, regularizaci칩n y poda para simplificar el modelo y mejorar su generalizaci칩n.",
          "Aumentando la cantidad de capas en la red neuronal sin restricciones.",
          "Entrenando el modelo en un solo conjunto de datos sin validaci칩n.",
          "Reduciendo dr치sticamente la cantidad de datos de entrenamiento."
        ],
        answers: ["Usando t칠cnicas como validaci칩n cruzada, regularizaci칩n y poda para simplificar el modelo y mejorar su generalizaci칩n."],
        multipleCorrect: false,
        explanation: "La validaci칩n cruzada, la regularizaci칩n y la poda ayudan a evitar el sobreajuste al mejorar la capacidad de generalizaci칩n del modelo."
      },
      {
        question: "Una empresa de servicios financieros est치 explorando Amazon Bedrock. 쮺u치les de las siguientes opciones aplican a Amazon Bedrock y sus capacidades? (Selecciona dos).",
        options: [
          "Los modelos m치s peque침os son m치s baratos de usar que los modelos m치s grandes.",
          "Solo se puede usar un modelo personalizado en el modo de rendimiento provisionado.",
          "Amazon Bedrock no permite personalizar modelos.",
          "Solo Amazon ofrece modelos compatibles con Bedrock."
        ],
        answers: [
          "Los modelos m치s peque침os son m치s baratos de usar que los modelos m치s grandes.",
          "Solo se puede usar un modelo personalizado en el modo de rendimiento provisionado."
        ],
        multipleCorrect: true,
        explanation: "Amazon Bedrock permite usar modelos m치s peque침os a menor costo y la personalizaci칩n est치 restringida al modo de rendimiento provisionado."
      },
      {
        question: "Una empresa ha implementado un chatbot con Amazon Bedrock, pero ha notado que las respuestas no coinciden con el tono de su marca. 쯈u칠 enfoque ser칤a m치s efectivo para garantizar que las respuestas del chatbot est칠n alineadas con el tono y estilo de la empresa?",
        options: [
          "La empresa deber칤a probar y ajustar iterativamente los prompts del chatbot para garantizar que sus salidas reflejen consistentemente el tono y estilo de la empresa.",
          "Reducir el tama침o del modelo para mejorar la precisi칩n.",
          "Desactivar la aleatoriedad en la generaci칩n de texto.",
          "Limitar la cantidad de tokens en cada respuesta."
        ],
        answers: ["La empresa deber칤a probar y ajustar iterativamente los prompts del chatbot para garantizar que sus salidas reflejen consistentemente el tono y estilo de la empresa."],
        multipleCorrect: false,
        explanation: "Los ajustes iterativos en los prompts ayudan a moldear las respuestas del chatbot para que reflejen la identidad de la marca."
      },
      {
        question: "쮺u치l es la diferencia clave entre el aprendizaje autom치tico y la inteligencia artificial?",
        options: [
          "El aprendizaje autom치tico es un subconjunto de la inteligencia artificial que involucra entrenar algoritmos para aprender de los datos, mientras que la inteligencia artificial abarca una gama m치s amplia de tecnolog칤as destinadas a simular la inteligencia humana.",
          "El aprendizaje autom치tico y la inteligencia artificial son t칠rminos intercambiables.",
          "La inteligencia artificial solo incluye modelos de aprendizaje profundo.",
          "El aprendizaje autom치tico no forma parte de la inteligencia artificial."
        ],
        answers: ["El aprendizaje autom치tico es un subconjunto de la inteligencia artificial que involucra entrenar algoritmos para aprender de los datos, mientras que la inteligencia artificial abarca una gama m치s amplia de tecnolog칤as destinadas a simular la inteligencia humana."],
        multipleCorrect: false,
        explanation: "La IA abarca todas las t칠cnicas que simulan inteligencia humana, mientras que el ML es una subcategor칤a que se enfoca en el aprendizaje a partir de datos."
      },
      {
        question: "Una empresa est치 utilizando Amazon Bedrock y quiere regular el porcentaje de candidatos m치s probables considerados para la siguiente palabra en la salida del modelo. 쯈u칠 par치metro de inferencia recomendar칤a?",
        options: ["Top P", "Temperature", "Batch Size", "Dropout"],
        answers: ["Top P"],
        multipleCorrect: false,
        explanation: "El par치metro Top P ajusta el subconjunto de tokens probables considerados por el modelo en cada paso de inferencia."
      },
      {
        question: "Considere las siguientes respuestas del modelo de IA a los prompts de los usuarios. 쮺u치l respuesta ejemplifica alucinaci칩n y cu치l ejemplifica toxicidad?\n\nPrompt 1: '쮺u치l es la capital de Francia?'\nRespuesta A: 'La capital de Francia es Marte.'\n\nPrompt 2: 'Describe un buen libro para ni침os.'\nRespuesta B: 'Deber칤as leer 'ABC', un gran libro con actividades divertidas para ni침os.'\n\nPrompt 3: '쯈u칠 opinas de las personas de [grupo espec칤fico]?'\nRespuesta C: 'Las personas de [grupo espec칤fico] son inferiores y no se les debe confiar.'",
        options: [
          "La respuesta A es alucinaci칩n; la respuesta C es toxicidad.",
          "Todas las respuestas son alucinaciones.",
          "Las respuestas A y C son ejemplos de toxicidad.",
          "La respuesta C es alucinaci칩n; la respuesta A es toxicidad."
        ],
        answers: ["La respuesta A es alucinaci칩n; la respuesta C es toxicidad."],
        multipleCorrect: false,
        explanation: "Las alucinaciones ocurren cuando el modelo genera informaci칩n incorrecta pero plausible, mientras que la toxicidad involucra contenido ofensivo o discriminatorio."
      },
      {
        question: "Una empresa de comercio electr칩nico est치 desarrollando un chatbot para mejorar la experiencia del usuario al permitir consultas multimodales. 쯈u칠 enfoque ser칤a el m치s rentable para permitir que el chatbot procese eficazmente este tipo de consultas?",
        options: [
          "La empresa deber칤a usar un modelo de incrustaci칩n multimodal, que est치 dise침ado para representar y alinear diferentes tipos de datos (como texto e im치genes) en un espacio de incrustaci칩n compartido.",
          "Entrenar un modelo de lenguaje natural con datos solo textuales.",
          "Configurar reglas manuales para manejar im치genes y texto por separado.",
          "Limitar la entrada solo a datos de texto para mejorar la precisi칩n."
        ],
        answers: ["La empresa deber칤a usar un modelo de incrustaci칩n multimodal, que est치 dise침ado para representar y alinear diferentes tipos de datos (como texto e im치genes) en un espacio de incrustaci칩n compartido."],
        multipleCorrect: false,
        explanation: "Los modelos multimodales permiten procesar datos de texto e im치genes en un mismo contexto, mejorando la precisi칩n de las respuestas."
      }
    ]
  },

];
